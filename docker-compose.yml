
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.2.15
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"
    networks:
      - tfl-network 

  kafka:
    image: confluentinc/cp-kafka:7.2.15
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - tfl-network 

  debezium:
    image: debezium/connect:2.7.0.Final

    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      # KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      # VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
    depends_on: [kafka]
    ports:
      - 8083:8083
    networks:
      - tfl-network 
  
  schema-registry:
    image: confluentinc/cp-schema-registry:7.2.15
    environment:
      - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8081,http://localhost:8081
      - SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=kafka:9092
      - SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL=PLAINTEXT      
    ports:
      - 8081:8081
    depends_on: [zookeeper, kafka]
    networks:
      - tfl-network 
  
  kafka_manager:
    image: hlebalbau/kafka-manager:stable
    restart: always
    ports:
      - "9000:9000"
    depends_on:
      - zookeeper
      - kafka
    environment:
      ZK_HOSTS: "zookeeper:2181"
      APPLICATION_SECRET: "random-secret"
    command: -Dpidfile.path=/dev/null
    networks:
      - tfl-network 

  postgres:
    image: postgres:latest
    environment:
      POSTGRES_DB:  ${DB_MAIN}
      POSTGRES_USER:  ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
    env_file:
    - .env
    ports:
      - "5432:5432"
    networks:
      - tfl-network 

  producer:
    build: ./producer
    depends_on:
      - kafka
    env_file:
      - .env
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      API_ID: ${API_ID}
      API_KEY: ${API_KEY}
    restart: unless-stopped
    networks:
      - tfl-network 
      

  consumer:
    build: ./consumer
    depends_on:
      - kafka
      - postgres
    env_file:
      - .env
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      POSTGRES_HOST: ${DB_HOST}
      POSTGRES_DB:  ${DB_MAIN}
      POSTGRES_USER:  ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
    networks:
      - tfl-network 

  spark-app:
    build: ./spark-app
    depends_on:
      - kafka
    env_file:
      - .env
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
    restart: unless-stopped
    networks:
      - tfl-network 
  
  row-deletion:
    build: ./row-deletion
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      POSTGRES_HOST: ${DB_HOST}
      POSTGRES_DB:  ${DB_MAIN}
      POSTGRES_USER:  ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
    restart: unless-stopped
    networks:
      - tfl-network 

  dashboard:
    build: ./dashboard
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      POSTGRES_HOST: ${DB_HOST}
      POSTGRES_DB:  ${DB_MAIN}
      POSTGRES_USER:  ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
    ports:
      - "8501:8501"
    restart: unless-stopped
    networks:
      - tfl-network 
  
networks:
  tfl-network:
    external: true
