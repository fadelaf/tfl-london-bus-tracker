from kafka import KafkaConsumer
from pyspark.sql import SparkSession
from pyspark.sql import functions as sf


from kafka import KafkaConsumer
bootstrap_servers = ['localhost:29092']
topicName = "testing"
consumer = KafkaConsumer(topicName, auto_offset_reset='latest', 
                         bootstrap_servers = bootstrap_servers,
                          value_deserializer=lambda x: json.loads(x.decode('utf-8'))
            )





store = []


for i in consumer:
    store = i.value
    break


store


len(store)





import os
os.environ["JAVA_HOME"] = "/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home"
os.environ["PATH"] = os.environ["JAVA_HOME"] + "/bin:" + os.environ["PATH"]

spark = SparkSession.builder \
        .appName("LondonBusTracker") \
        .config("spark.jars", "/Users/fadelahmadf/Drivers/postgresql-42.7.3.jar")\
        .getOrCreate()



spark


store[0]


keys = ["vehicleId", "lineName", "stationName", "destinationName", "timeToStation", "expectedArrival", "timestamp",
        "towards","timeToLive"]


# Buat schema

from pyspark.sql.types import StructType,StructField, StructType, StringType, IntegerType, TimestampType
import pyspark.sql.functions as sf

schema = StructType([
            StructField("vehicleId",StringType(),True),
            StructField("lineName",StringType(),True),
            StructField("stationName",StringType(),True),
            StructField("destinationName",StringType(),True),
            StructField("timeToStation",IntegerType(),True),
            StructField("expectedArrival",StringType(),True),
            StructField("timestamp",StringType(),True),
            StructField("towards",StringType(),True),
            StructField("timeToLive",StringType(),True)])
 
#  ambil data yang mau diambil
bus_routes = []
for route in store:
    bus_route = {
        "vehicleId":route.get("vehicleId"),
        "lineName":route.get("lineName"),
        "stationName":route.get("stationName"),
        "destinationName": route.get("destinationName"),
        "timeToStation":route.get("timeToStation"),
        "expectedArrival":route.get("expectedArrival"),
        "timestamp":route.get("timestamp"),
        "towards":route.get("towards"),
        "timeToLive":route.get("timeToLive")   
    }

    bus_routes.append(bus_route)


bus_track = spark.createDataFrame(bus_routes, schema)
bus_track

# transformasi dulu

# jadiin dictionary lagi dalam list

# baru push ke storage


bus_track = spark.createDataFrame(bus_routes, schema)
bus_track

bus_track.toPandas()


bus_track.schema






bus_track = bus_track.withColumn("expectedArrival", sf.regexp_replace("expectedArrival","Z",""))\
         .withColumn("timeToLive", sf.regexp_replace("expectedArrival","Z",""))\
         .withColumn("timestamp", sf.regexp_replace("expectedArrival","Z",""))

bus_track = bus_track.withColumn("expectedArrival", sf.to_timestamp("expectedArrival","yyyy-MM-dd'T'HH:mm:ss"))\
         .withColumn("timeToLive", sf.to_timestamp("expectedArrival","yyyy-MM-dd'T'HH:mm:ss"))\
         .withColumn("timestamp", sf.to_timestamp("expectedArrival","yyyy-MM-dd'T'HH:mm:ss"))


bus_track = bus_track.withColumn("timeToStation", (sf.col("TimetoStation")/60).cast("int"))


bus_track.show()






bootstrap_servers = ['localhost:29092']
topic_name = 'tfl.clean.bus_arrival'

producer =  KafkaProducer(bootstrap_servers=bootstrap_servers,
                          value_serializer=lambda v: json.dumps(v).encode('utf-8')
                          )

producer.send(topic_name, bus_track)






